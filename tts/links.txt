jetson voice
https://github.com/dusty-nv/jetson-voice
https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/tts_en_fastpitch/files?version=1.0.0

Try to make NeMo\nemo\collections\tts\models\fastspeech2.py exportable and use in jetson-voice container
https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/core/export.html
https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/tts_en_fastspeech_2/files


https://forums.developer.nvidia.com/t/offline-speech-synthesis-tts/125370
I had a chance yesterday to try on NX for Mozilla TTS, NeMo TTS and Deepvoice 3.
Here is my data on inference with pre-trained models:
Mozilla TTS takes around 3-5 secs,
NeMo TTS is taking more than several minutes.
Deepvoice 3, is the best as of now, which is 1:1

mozilla/coqui TTS:
https://github.com/coqui-ai/TTS
docker images: https://tts.readthedocs.io/en/latest/docker_images.html
runs on jetson
benchmarks: https://github.com/coqui-ai/TTS/discussions/1698

# install coqui TTS:
docker: l4t-ml:r32.7.1-py3
# Docker container for ML on Nano:
sudo docker run --runtime nvidia -it --rm --network host --volume /home/pi/ml:/ml nvcr.io/nvidia/l4t-ml:r32.7.1-py3

# install pytorch without docker:
sudo apt-get install libopenblas-base libopenmpi-dev libomp-dev python3-pip
pip3 install Cython
pip3 install numpy

link from here: https://elinux.org/Jetson_Zoo (JetPack 4.4 / 4.4.1 / 4.5 / 4.5.1 / 4.6 # Python 3.6 # v1.10.0)
wget https://nvidia.box.com/shared/static/fjtbno0vpo676a25cgvuqc1wty0fkkg6.whl
mv fjtbno0vpo676a25cgvuqc1wty0fkkg6.whl torch-1.10.0-cp36-cp36m-linux_aarch64.whl
pip3 install torch-1.10.0-cp36-cp36m-linux_aarch64.whl

# install torchaudio (part from here: https://github.com/dusty-nv/jetson-containers/blob/1e10908a104494a883f6855d1e9947827f2a17bc/Dockerfile.pytorch)
sudo apt install ffmpeg libavformat-dev libavcodec-dev libavutil-dev libavdevice-dev libavfilter-dev
sudo apt-get install -y --no-install-recommends cmake sox libsox-dev libsox-fmt-all
pip3 install scikit-build
pip3 install ninja==1.10.0
git clone --recursive -b 0.10.0 https://github.com/pytorch/audio torchaudio
cd torchaudio
python3 setup.py install
cd ..

# install numba (https://github.com/epicmario7133/jetson-nano-tricks/blob/main/README.md)
git clone https://github.com/wjakob/tbb.git
cd tbb/build
cmake ..
make -j
sudo make install
sudo apt install llvm-10
export LLVM_CONFIG=/usr/bin/llvm-config-10
pip3 install llvmlite
pip3 install Cython
pip3 install numba

sudo apt-get install gcc gfortran python-dev libopenblas-dev liblapack-dev cython libffi-dev
pip3 install scipy==1.4.0
pip3 install trainer --no-deps

git clone https://github.com/coqui-ai/TTS.git
cd TTS
git checkout tags/v0.6.1
remove requirement: mecab-python3==1.0.3
python3 -m pip install -r requirements.txt
pip3 install decorator==4.3
python3 setup.py develop

python3 /ml/docktest/TTS/TTS/bin/synthesize_server.py --model_name "tts_models/en/ljspeech/glow-tts" --vocoder_name "vocoder_models/en/ljspeech/multiband-melgan"

23s: python3 TTS/TTS/bin/synthesize.py --text "The first manned Moon landing was Apollo 11 on July, 20 1969. The first human to step on the Moon was astronaut Neil Armstrong followed second by Buzz Aldrin. They landed in the Sea of Tranquility with their lunar module the Eagle. They were on the lunar surface for 2.25 hours and collected 50 pounds of moon rocks." --model_name "tts_models/en/ljspeech/fast_pitch" --vocoder_name "vocoder_models/en/ljspeech/hifigan_v2"     --out_path coqui_fast_pitch_hifigan_v2_23seconds.wav
16s: python3 TTS/TTS/bin/synthesize.py --text "The first manned Moon landing was Apollo 11 on July, 20 1969. The first human to step on the Moon was astronaut Neil Armstrong followed second by Buzz Aldrin. They landed in the Sea of Tranquility with their lunar module the Eagle. They were on the lunar surface for 2.25 hours and collected 50 pounds of moon rocks." --model_name "tts_models/en/ljspeech/glow-tts" --vocoder_name "vocoder_models/en/ljspeech/multiband-melgan" --out_path coqui_glow_melgan_16seconds.wav
69s: python3 TTS/TTS/bin/synthesize.py --text "The first manned Moon landing was Apollo 11 on July, 20 1969. The first human to step on the Moon was astronaut Neil Armstrong followed second by Buzz Aldrin. They landed in the Sea of Tranquility with their lunar module the Eagle. They were on the lunar surface for 2.25 hours and collected 50 pounds of moon rocks." --model_name "tts_models/en/ljspeech/glow-tts" --vocoder_name "vocoder_models/en/ljspeech/univnet"          --out_path coqui_glow_univnet.wav
18s: python3 TTS/TTS/bin/synthesize.py --text "The first manned Moon landing was Apollo 11 on July, 20 1969. The first human to step on the Moon was astronaut Neil Armstrong followed second by Buzz Aldrin. They landed in the Sea of Tranquility with their lunar module the Eagle. They were on the lunar surface for 2.25 hours and collected 50 pounds of moon rocks." --model_name "tts_models/en/ljspeech/speedy-speech" --vocoder_name "vocoder_models/en/ljspeech/hifigan_v2"  --out_path coqui_speedy_hifigan_v2.wav

python3 TTS/TTS/bin/synthesize.py --text "Hello! How are you doing? I don't know what to say now. 1 plus 2 is not equal to 42. The Jetson Nano is a nice device, but it is so painful to program it." --model_name "tts_models/en/ljspeech/glow-tts" --vocoder_name "vocoder_models/en/ljspeech/multiband-melgan" --out_path coqui_glow_melgan_hello.wav

cp -R /root/.local/share/tts/ ttsshare
mv /root/.local/share/tts ttsshare

mkdir -p /root/.local/share/tts
cp -R ttsshare/* /root/.local/share/tts/

This makes inference faster:
import torch
torch.set_num_threads(1)

Running Coqui TTS in a Docker container on NVIDIA Jetson device
https://www.youtube.com/watch?v=cWq5E90AIGE
https://github.com/thorstenMueller/Thorsten-Voice/blob/master/helperScripts/Dockerfile.Jetson-Coqui

silero TTS (uses pytorch)
https://github.com/snakers4/silero-models#text-to-speech
benötigt JetPack 4.6.1 (L4T R32.7.1) l4t-ml:r32.7.1-py3
https://news.ycombinator.com/item?id=31807201


deep voice3. samples sound kinda bad.
Tried to install on Jetson, but failed.
https://r9y9.github.io/deepvoice3_pytorch/

good quality, but very slow
https://github.com/neonbjb/tortoise-tts



Coqui TTS 0.6.2 models:
Name format: type/language/dataset/model
 1: tts_models/multilingual/multi-dataset/your_tts
 2: tts_models/en/ek1/tacotron2
 3: tts_models/en/ljspeech/tacotron2-DDC
 4: tts_models/en/ljspeech/tacotron2-DDC_ph
 5: tts_models/en/ljspeech/glow-tts
 6: tts_models/en/ljspeech/speedy-speech
 7: tts_models/en/ljspeech/tacotron2-DCA
 8: tts_models/en/ljspeech/vits
 9: tts_models/en/ljspeech/fast_pitch
 10: tts_models/en/vctk/vits
 11: tts_models/en/vctk/fast_pitch
 12: tts_models/en/sam/tacotron-DDC
 13: tts_models/es/mai/tacotron2-DDC
 14: tts_models/fr/mai/tacotron2-DDC
 15: tts_models/uk/mai/glow-tts
 16: tts_models/zh-CN/baker/tacotron2-DDC-GST
 17: tts_models/nl/mai/tacotron2-DDC
 18: tts_models/de/thorsten/tacotron2-DCA
 19: tts_models/ja/kokoro/tacotron2-DDC
 20: tts_models/tr/common-voice/glow-tts
 21: tts_models/it/mai_female/glow-tts
 22: tts_models/it/mai_female/vits
 23: tts_models/it/mai_male/glow-tts
 24: tts_models/it/mai_male/vits
 25: tts_models/ewe/openbible/vits
 26: tts_models/hau/openbible/vits
 27: tts_models/lin/openbible/vits
 28: tts_models/tw_akuapem/openbible/vits
 29: tts_models/tw_asante/openbible/vits
 30: tts_models/yor/openbible/vits
 1: vocoder_models/universal/libri-tts/wavegrad
 2: vocoder_models/universal/libri-tts/fullband-melgan
 3: vocoder_models/en/ek1/wavegrad
 4: vocoder_models/en/ljspeech/multiband-melgan
 5: vocoder_models/en/ljspeech/hifigan_v2
 6: vocoder_models/en/ljspeech/univnet
 7: vocoder_models/en/vctk/hifigan_v2
 8: vocoder_models/en/sam/hifigan_v2
 9: vocoder_models/nl/mai/parallel-wavegan
 10: vocoder_models/de/thorsten/wavegrad
 11: vocoder_models/de/thorsten/fullband-melgan
 12: vocoder_models/ja/kokoro/hifigan_v1
 13: vocoder_models/uk/mai/multiband-melgan
 14: vocoder_models/tr/common-voice/hifigan
  #############################################################
 Name format: type/language/dataset/model
 1: tts_models/multilingual/multi-dataset/your_tts
 2: tts_models/en/ek1/tacotron2
 3: tts_models/en/ljspeech/tacotron2-DDC
 4: tts_models/en/ljspeech/tacotron2-DDC_ph
 5: tts_models/en/ljspeech/glow-tts
 6: tts_models/en/ljspeech/speedy-speech
 7: tts_models/en/ljspeech/tacotron2-DCA
 8: tts_models/en/ljspeech/vits
 9: tts_models/en/ljspeech/fast_pitch
 10: tts_models/en/vctk/vits
 11: tts_models/en/vctk/fast_pitch
 12: tts_models/en/sam/tacotron-DDC
 13: tts_models/es/mai/tacotron2-DDC
 1: vocoder_models/universal/libri-tts/wavegrad
 2: vocoder_models/universal/libri-tts/fullband-melgan
 3: vocoder_models/en/ek1/wavegrad
 4: vocoder_models/en/ljspeech/multiband-melgan
 5: vocoder_models/en/ljspeech/hifigan_v2
 6: vocoder_models/en/ljspeech/univnet
 7: vocoder_models/en/vctk/hifigan_v2
 8: vocoder_models/en/sam/hifigan_v2


# Pure GPT base TTS, but way too slow for Jetson Nano
https://github.com/suno-ai/bark

waiting music source:
https://pixabay.com/music/bossa-nova-waiting-music-116216/

finish sound source:
alarm07.wav in Windows Media folder